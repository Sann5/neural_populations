# Notes on paper: SOFTHEBB: BAYESIAN INFERENCE IN UNSUPERVISED HEBBIAN SOFT WINNER-TAKE-ALL NETWORKS

- it seems that our online WTA that is already analogous to kmeans/EM, simply for one data poin isntead of many. Does the softenss already take care of uneaven membership assignmet problem? <- this by itself was waht the whole project was intially about
- food for tought: what happens if instead of considering the input of the WTA as individual neurons we consider them to be population codes? what power does this intyerpetation offer? or rather does it confound the interpretation more?
- food for tought: the advantage of taking this to the ML relm is that it offes conceptual tools to reason about the underlyuing learing proces, namely the optimized quantities and factors involved. 
- the papaer is very similar to what we want to do but we could offer more interpretation, namly point out more relationships between our toy WTA model choice and a plaussible biological implementation. 